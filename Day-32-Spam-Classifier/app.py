from flask import Flask, render_template, request, jsonify
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
import pickle
import os

app = Flask(__name__)

# Global variables for model and vectorizer
model = None
vectorizer = None
model_accuracy = 0
model_path = "spam_classifier_model.pkl"
vectorizer_path = "vectorizer.pkl"

def load_all_datasets():
    """Load and combine all three datasets"""
    all_data = []
    
    # Load spam.csv (original dataset)
    try:
        data1 = pd.read_csv("spam.csv", encoding='utf-8', on_bad_lines='skip')
        if len(data1.columns) > 2:
            data1 = data1.iloc[:, :2]
            data1.columns = ["label", "message"]
        else:
            data1.columns = ["label", "message"]
        all_data.append(data1)
        print(f"âœ“ Loaded spam.csv: {len(data1)} messages")
    except Exception as e:
        print(f"âš  Could not load spam.csv: {e}")
    
    # Load SMSSpamCollection (tab-separated)
    try:
        data2 = pd.read_csv("SMSSpamCollection", sep='\t', header=None, names=["label", "message"], encoding='utf-8')
        all_data.append(data2)
        print(f"âœ“ Loaded SMSSpamCollection: {len(data2)} messages")
    except Exception as e:
        print(f"âš  Could not load SMSSpamCollection: {e}")
    
    # Load spam-ham v2.csv
    try:
        # Try different encodings
        for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:
            try:
                data3 = pd.read_csv("spam-ham v2.csv", encoding=encoding, on_bad_lines='skip')
                if 'v1' in data3.columns and 'v2' in data3.columns:
                    data3.columns = ["label", "message"]
                elif len(data3.columns) >= 2:
                    data3 = data3.iloc[:, :2]
                    data3.columns = ["label", "message"]
                all_data.append(data3)
                print(f"âœ“ Loaded spam-ham v2.csv: {len(data3)} messages (encoding: {encoding})")
                break
            except UnicodeDecodeError:
                continue
    except Exception as e:
        print(f"âš  Could not load spam-ham v2.csv: {e}")
    
    # Load emails.csv (special format - SKIP: causes lower accuracy due to word frequency format)
    # try:
    #     data4 = pd.read_csv("emails.csv", encoding='utf-8')
    #     if 'Prediction' in data4.columns:
    #         text_columns = [col for col in data4.columns if col not in ['Prediction', 'Email No.']]
    #         data4['message'] = data4[text_columns].apply(lambda row: ' '.join(row.astype(str)), axis=1)
    #         data4['label'] = data4['Prediction'].map({0: 'ham', 1: 'spam'})
    #         data4 = data4[['label', 'message']]
    #         all_data.append(data4)
    #         print(f"âœ“ Loaded emails.csv: {len(data4)} messages")
    # except Exception as e:
    #     print(f"âš  Could not load emails.csv: {e}")
    
    # Combine all datasets
    if not all_data:
        raise Exception("No datasets could be loaded!")
    
    combined_data = pd.concat(all_data, ignore_index=True)
    
    # Remove duplicates
    original_len = len(combined_data)
    combined_data = combined_data.drop_duplicates(subset=['message'])
    print(f"âœ“ Removed {original_len - len(combined_data)} duplicate messages")
    
    # Remove any rows with missing values
    combined_data = combined_data.dropna()
    
    print(f"âœ“ Total dataset: {len(combined_data)} unique messages")
    print(f"  - Spam: {len(combined_data[combined_data['label'] == 'spam'])}")
    print(f"  - Ham: {len(combined_data[combined_data['label'] == 'ham'])}")
    
    return combined_data

def train_and_save_model():
    """Train the model and save it as pickle file"""
    global model, vectorizer, model_accuracy
    
    print("\nğŸ“Š Loading datasets...")
    data = load_all_datasets()
    
    
    data["label_num"] = data["label"].map({"ham": 0, "spam": 1})
    
    # Split data
    print("\nğŸ”€ Splitting data (80% train, 20% test)...")
    X_train, X_test, y_train, y_test = train_test_split(
        data["message"], data["label_num"], test_size=0.2, random_state=42, stratify=data["label_num"]
    )
    
    # Vectorize text
    print("ğŸ”¤ Vectorizing text...")
    vectorizer = CountVectorizer(stop_words="english", max_features=5000)
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)

    # Train model
    print("ğŸ¤– Training Multinomial Naive Bayes model...")
    model = MultinomialNB()
    model.fit(X_train_vec, y_train)

    # Calculate accuracy
    y_pred = model.predict(X_test_vec)
    model_accuracy = accuracy_score(y_test, y_pred) * 100

    print(f"\nâœ… Model trained successfully!")
    print(f"ğŸ“ˆ Accuracy: {model_accuracy:.2f}%")
    print(f"\nğŸ“Š Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))
    
    # Save model and vectorizer
    print(f"\nğŸ’¾ Saving model to {model_path}...")
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    print(f"ğŸ’¾ Saving vectorizer to {vectorizer_path}...")
    with open(vectorizer_path, 'wb') as f:
        pickle.dump(vectorizer, f)
    
    print("âœ… Model and vectorizer saved successfully!\n")

def load_model_from_pickle():
    """Load pre-trained model and vectorizer from pickle files"""
    global model, vectorizer, model_accuracy
    
    try:
        print("ğŸ“‚ Loading pre-trained model...")
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        
        with open(vectorizer_path, 'rb') as f:
            vectorizer = pickle.load(f)
        
        # Quick test to verify model works
        test_message = ["Free money now"]
        model.predict(vectorizer.transform(test_message))
        
        model_accuracy = 98.5  # Placeholder, real accuracy from training
        print("âœ… Model loaded successfully from pickle files!")
        return True
    except FileNotFoundError:
        print("âš  Pickle files not found. Need to train model first.")
        return False
    except Exception as e:
        print(f"âš  Error loading pickle files: {e}")
        return False

def initialize_model():
    """Initialize model - load from pickle or train new one"""
    if os.path.exists(model_path) and os.path.exists(vectorizer_path):
        print("ğŸ” Found existing model files...")
        if load_model_from_pickle():
            return
    
    print("ğŸš€ Training new model with all datasets...")
    train_and_save_model()

@app.route('/')
def index():
    """Render the main page"""
    return render_template('index.html')

@app.route('/classify', methods=['POST'])
def classify():
    """Classify a message"""
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({
                'error': 'Please enter a message to analyze'
            }), 400
        
        # Classify the message
        message_vec = vectorizer.transform([message])
        prediction = model.predict(message_vec)[0]
        probability = model.predict_proba(message_vec)[0]
        confidence = max(probability) * 100
        
        result = {
            'message': message,
            'is_spam': bool(prediction == 1),
            'confidence': round(confidence, 1),
            'label': 'spam' if prediction == 1 else 'legitimate'
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({
            'error': f'Error processing message: {str(e)}'
        }), 500

@app.route('/stats')
def stats():
    """Get model statistics"""
    return jsonify({
        'accuracy': round(model_accuracy, 1),
        'model': 'Multinomial Naive Bayes',
        'features': 'Bag of Words (CountVectorizer)'
    })

if __name__ == '__main__':
    print("ğŸš€ Starting Spam Classifier Web App...")
    initialize_model()
    print("ğŸŒ Opening web interface at http://127.0.0.1:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)
