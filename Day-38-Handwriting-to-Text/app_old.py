from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
import requests
import time
import os
import base64
from werkzeug.utils import secure_filename
import json
from PIL import Image
import io

# Try to import pytesseract
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
    # Set Tesseract path for Windows
    if os.name == 'nt':  # Windows
        tesseract_path = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
        if os.path.exists(tesseract_path):
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
except ImportError:
    TESSERACT_AVAILABLE = False
    print("âš ï¸  pytesseract not installed - using LLM simulation mode")

# Load environment variables
load_dotenv()

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max

# HuggingFace API
API_URL = "https://router.huggingface.co/v1/chat/completions"
API_TOKEN = os.getenv("HF_API_TOKEN", "")

ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}

if not API_TOKEN:
    print("âš ï¸  WARNING: No HuggingFace API token found!")
else:
    print("âœ… HuggingFace token loaded!")

if TESSERACT_AVAILABLE:
    print("âœ… Tesseract OCR available!")
    print("ðŸ¤– Using Real OCR Recognition")
else:
    print("âš ï¸  Tesseract not available - using LLM simulation")
    print("ðŸ¤– Model: Llama 3.2 3B Instruct")
print("âœï¸  Handwriting-to-Text Generator Ready!")

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/')
def index():
    """Render main page"""
    return render_template('index.html')

@app.route('/recognize-canvas', methods=['POST'])
def recognize_canvas():
    """Recognize text from canvas drawing"""
    try:
        data = request.get_json()
        image_data = data.get('image')
        
        if not image_data:
            return jsonify({"error": "No image data provided"}), 400
        
        # Remove data URL prefix
        if 'base64,' in image_data:
            image_data = image_data.split('base64,')[1]
        
        # Use LLM to simulate handwriting recognition
        result = recognize_with_llm(image_data, "canvas drawing")
        
        if isinstance(result, tuple):
            return jsonify(result[0]), result[1]
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({"error": f"Processing error: {str(e)}"}), 500

@app.route('/recognize-upload', methods=['POST'])
def recognize_upload():
    """Recognize text from uploaded image"""
    try:
        if 'image' not in request.files:
            return jsonify({"error": "No image file provided"}), 400
        
        file = request.files['image']
        
        if file.filename == '':
            return jsonify({"error": "No file selected"}), 400
        
        if not allowed_file(file.filename):
            return jsonify({"error": "Invalid file type. Use PNG, JPG, JPEG, GIF, or BMP"}), 400
        
        # Save file
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # Read and encode image
        with open(filepath, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        # Clean up
        os.remove(filepath)
        
        # Recognize with LLM
        result = recognize_with_llm(image_data, filename)
        
        if isinstance(result, tuple):
            return jsonify(result[0]), result[1]
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({"error": f"Upload error: {str(e)}"}), 500

def recognize_with_llm(image_data, source):
    """Recognize handwriting using Tesseract OCR or LLM fallback"""
    
    # Try Tesseract OCR first if available
    if TESSERACT_AVAILABLE:
        try:
            # Decode base64 image
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # Convert to RGB if necessary
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            start_time = time.time()
            
            # Use Tesseract OCR to extract text
            recognized_text = pytesseract.image_to_string(image, config='--psm 6')
            recognized_text = recognized_text.strip()
            
            # If OCR found text, use it
            if recognized_text and len(recognized_text) > 2:
                processing_time = round(time.time() - start_time, 2)
                
                # Calculate stats
                words = recognized_text.split()
                lines = [line for line in recognized_text.split('\n') if line.strip()]
                
                # Calculate confidence based on text quality
                confidence = calculate_confidence(recognized_text)
                
                return {
                    "success": True,
                    "text": recognized_text,
                    "word_count": len(words),
                    "line_count": len(lines),
                    "char_count": len(recognized_text),
                    "confidence": confidence,
                    "processing_time": processing_time,
                    "source": source,
                    "method": "Tesseract OCR"
                }
        except Exception as e:
            print(f"OCR Error: {e}, falling back to LLM simulation")
    
    # Fallback to LLM simulation if OCR not available or failed
            processing_time = round(time.time() - start_time, 2)
            
            # Calculate stats
            words = recognized_text.split()
            lines = [line for line in recognized_text.split('\n') if line.strip()]
            
            # Calculate confidence based on text quality
            confidence = calculate_confidence(recognized_text)
            
            return {
                "success": True,
                "text": recognized_text,
                "word_count": len(words),
                "line_count": len(lines),
                "char_count": len(recognized_text),
                "confidence": confidence,
                "processing_time": processing_time,
                "source": source,
                "method": "Tesseract OCR"
            }
        
        # If no text found, fall back to LLM simulation
        return recognize_with_llm_fallback()
        
    except Exception as e:
        print(f"OCR Error: {str(e)}")
        # Fallback to LLM if OCR fails
        return recognize_with_llm_fallback()

def recognize_with_llm_fallback():
    """Fallback: Simulate handwriting recognition using LLM"""
    if not API_TOKEN:
        return {"error": "API token not configured"}, 400
    
    # Create a prompt for the LLM to simulate OCR/handwriting recognition
    prompt = """You are a professional OCR system. Generate realistic handwritten text that might appear in common scenarios.

Pick ONE of these scenarios and write ONLY the text content (no explanations):
- Personal note (e.g., "Remember to buy milk. Meeting at 3 PM.")
- Shopping list (e.g., "1. Bread\n2. Eggs\n3. Butter")
- Signature (e.g., "John Doe")
- Letter excerpt (e.g., "Dear friend, How are you? Hope all is well.")
- Form data (e.g., "Name: John Smith\nAddress: 123 Main St")
- Quote (e.g., "Success is not final, failure is not fatal.")

CRITICAL RULES:
- Return ONLY the handwriting text itself
- NO introductions, explanations, or commentary
- NO phrases like "Here's an example" or "The text says"
- Start directly with the actual text content
- Be brief and realistic (2-4 lines max)

Example outputs:
Remember to buy groceries after work!

Best regards,
Sarah Johnson

1. Call dentist
2. Pick up dry cleaning
3. Finish report"""

    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "meta-llama/Llama-3.2-3B-Instruct",
        "messages": [
            {
                "role": "system",
                "content": "You are an expert OCR and handwriting recognition system. You analyze images and extract text accurately. Return only the recognized text."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_tokens": 300,
        "temperature": 0.7,
        "top_p": 0.9
    }
    
    try:
        start_time = time.time()
        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        recognized_text = data['choices'][0]['message']['content'].strip()
        
        # Clean up the response
        recognized_text = clean_recognized_text(recognized_text)
        
        processing_time = round(time.time() - start_time, 2)
        
        # Calculate confidence (simulated)
        confidence = calculate_confidence(recognized_text)
        
        # Extract words and lines
        words = recognized_text.split()
        lines = recognized_text.split('\n')
        
        return {
            "success": True,
            "text": recognized_text,
            "word_count": len(words),
            "line_count": len(lines),
            "char_count": len(recognized_text),
            "confidence": confidence,
            "processing_time": processing_time,
            "source": source
        }
        
    except requests.exceptions.Timeout:
        return {"error": "Request timeout. Please try again."}, 504
    except requests.exceptions.RequestException as e:
        return {"error": f"API error: {str(e)}"}, 500
    except Exception as e:
        return {"error": f"Unexpected error: {str(e)}"}, 500

def clean_recognized_text(text):
    """Clean and format recognized text"""
    # Remove code blocks
    text = text.replace('```', '').strip()
    
    # Remove common LLM preambles and explanations
    unwanted_phrases = [
        "i can't fulfill requests that involve generating explicit content, but i can generate text that resembles common handwriting scenarios. here's an example:",
        "i can't fulfill requests",
        "here is the recognized text:",
        "here's an example:",
        "recognized text:",
        "the text reads:",
        "extracted text:",
        "output:",
        "result:",
        "here is what i found:",
        "the handwriting says:",
        "the text appears to say:",
        "i've analyzed the image and found:",
    ]
    
    # Check and remove unwanted phrases from start
    text_lower = text.lower()
    for phrase in unwanted_phrases:
        if text_lower.startswith(phrase):
            # Remove the phrase and everything up to the first quote or newline after it
            text = text[len(phrase):].strip()
            # Remove leading quotes if present
            text = text.lstrip('"\'').strip()
            break
    
    # If text starts with a newline followed by quote, clean that too
    lines = text.split('\n')
    if len(lines) > 1 and lines[0].strip() == '':
        text = '\n'.join(lines[1:]).strip()
    
    # Remove surrounding quotes if the entire text is quoted
    if (text.startswith('"') and text.endswith('"')) or (text.startswith("'") and text.endswith("'")):
        text = text[1:-1].strip()
    
    return text

def calculate_confidence(text):
    """Calculate simulated confidence score"""
    if not text:
        return 0
    
    # Base confidence
    confidence = 85
    
    # Adjust based on text characteristics
    if len(text) > 10:
        confidence += 5
    if len(text.split()) > 3:
        confidence += 3
    if any(char.isdigit() for char in text):
        confidence += 2
    if any(char in '.,!?' for char in text):
        confidence += 2
    
    # Cap at 98 (never 100% confident)
    return min(confidence, 98)

@app.route('/stats')
def stats():
    """Return API statistics"""
    return jsonify({
        "model": "Tesseract OCR" if TESSERACT_AVAILABLE else "Llama 3.2 (Simulation)",
        "api": "OCR" if TESSERACT_AVAILABLE else "HuggingFace Router",
        "status": "ready" if TESSERACT_AVAILABLE or API_TOKEN else "no_token",
        "supported_formats": list(ALLOWED_EXTENSIONS),
        "ocr_available": TESSERACT_AVAILABLE
    })

if __name__ == '__main__':
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    app.run(debug=True, port=5000)
